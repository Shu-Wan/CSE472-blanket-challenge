{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Final Project - example solution\n",
    "\n",
    "This notebook demonstrates the integration of TabPFN for two tasks:\n",
    "1.  **Regression**: Predicting the target variable `y`.\n",
    "2.  **Markov Blanket (MB) Discovery**: Identifying the optimal feature set using TabPFN embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from blanket.plots import plot_graph\n",
    "from blanket.metrics import rmse, jaccard_score\n",
    "\n",
    "from tabpfn import TabPFNRegressor\n",
    "from tabpfn_extensions.embedding import TabPFNEmbedding\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "develop = load_dataset(\"CSE472-blanket-challenge/final-dataset\", 'develop', split='train')\n",
    "submit = load_dataset(\"CSE472-blanket-challenge/final-dataset\", 'submit', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(develop), len(submit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "[ðŸ¤— Dataset](CSE472-blanket-challenge/final-dataset)\n",
    "\n",
    "Develop: 182 datasets\n",
    "\n",
    "- X_train, y_train, X_test, y_test, metadata\n",
    "\n",
    "Subumit: 46 datasets\n",
    "\n",
    "- X_train, y_train, X_test\n",
    "\n",
    "Develop and Submit use the same script for data generation.\n",
    "\n",
    "For generation details, refer to <https://huggingface.co/datasets/CSE472-blanket-challenge/final-dataset>\n",
    "\n",
    "You task:\n",
    "\n",
    "1. Train a model using `develop` to predict `y` and `markov_blanket`\n",
    "2. Test your model on `submit`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Test Case\n",
    "example_data = develop[89]\n",
    "X_train = np.asarray(example_data['X_train'])\n",
    "y_train = np.asarray(example_data['y_train'])\n",
    "X_test = np.asarray(example_data['X_test'])\n",
    "y_test = np.asarray(example_data['y_test'])\n",
    "\n",
    "print(f\"Example data id: {example_data['data_id']}\")\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "print(f\"Env: {example_data['environment']}\")\n",
    "print(f\"SCM: {example_data['scm']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Causal Graph\n",
    "plot_graph(example_data['adjacency_matrix'], title=f\"Causal Graph: {example_data['graph_id']}\", figsize=(8, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## TabPFN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.model_loading import ModelSource\n",
    "regressor_models = ModelSource.get_regressor_v2_5()\n",
    "\n",
    "print(\"Available TabPFN Regressor Models:\\n\", )\n",
    "for model_name in regressor_models.filenames:\n",
    "    print(f\"  {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "TabPFN load `tabpfn-v2.5-regressor-v2.5_default.ckpt` by default\n",
    "\n",
    "the `real` variant are fine-tuned on real world dataset\n",
    "\n",
    "For details, see TabPFN's [technical report](https://storage.googleapis.com/prior-labs-tabpfn-public/reports/TabPFN_2_5_tech_report.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "TABPFN_MODEL_CACHE_DIR = Path(os.getenv(\"TABPFN_MODEL_CACHE_DIR\", None))\n",
    "\n",
    "model_path = hf_hub_download(repo_id=regressor_models.repo_id, filename=\"tabpfn-v2.5-regressor-v2.5_real.ckpt\", local_dir=TABPFN_MODEL_CACHE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### TabPFN toy example\n",
    "mode 1: in context learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabpfn is a subclass of sklearn estimators, so it has the same API\n",
    "# toy example\n",
    "regressor_config = {\n",
    "        \"ignore_pretraining_limits\": True,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"n_estimators\": 24,\n",
    "        \"random_state\":42,\n",
    "        \"inference_precision\": \"auto\"\n",
    "    }\n",
    "\n",
    "regressor = TabPFNRegressor(model_path = model_path, **regressor_config)\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "preds = regressor.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\", rmse(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "mode 2: fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.utils import meta_dataset_collator\n",
    "from tabpfn.finetune_utils import clone_model_for_evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "regressor_config = {\n",
    "        \"ignore_pretraining_limits\": True,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"n_estimators\": 24,\n",
    "        \"random_state\":42,\n",
    "        \"inference_precision\": \"auto\"\n",
    "    }\n",
    "\n",
    "# --- Setup model ---\n",
    "regressor = TabPFNRegressor(\n",
    "    **regressor_config,\n",
    "    fit_mode=\"batched\", differentiable_input=False\n",
    ")\n",
    "# initialize model weights\n",
    "regressor._initialize_model_variables()\n",
    "\n",
    "optimizer = Adam(regressor.model_.parameters(), lr=1.5e-6)\n",
    "\n",
    "# --- Dataloader setup ---\n",
    "datasets = regressor.get_preprocessed_datasets(X_train, y_train, train_test_split, 10000)\n",
    "loader = DataLoader(datasets, batch_size=1, collate_fn=meta_dataset_collator)\n",
    "\n",
    "# --- Fine-tuning loop ---\n",
    "for epoch in tqdm(range(10), desc=\"Fine-tuning Epochs\", leave=False):\n",
    "    for data_batch in tqdm(loader, desc=f\"Epoch {epoch}\"):\n",
    "        optimizer.zero_grad()\n",
    "        (X_tr, X_te, y_tr, y_te, cat_ixs, confs, raw_space, znorm_space, _, _) = data_batch\n",
    "        regressor.raw_space_bardist_ = raw_space[0]\n",
    "        regressor.znorm_space_bardist_ = znorm_space[0]\n",
    "        regressor.fit_from_preprocessed(X_tr, y_tr, cat_ixs, confs)\n",
    "        preds, _, _ = regressor.forward(X_te)\n",
    "        loss_fn = znorm_space[0]\n",
    "        loss = loss_fn(preds, y_te.to(regressor.device)).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# --- Evaluation ---\n",
    "eval_reg = clone_model_for_evaluation(regressor, {}, TabPFNRegressor)\n",
    "eval_reg.fit(X_train, y_train)\n",
    "preds = eval_reg.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\", rmse(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "fine-tuning indeed improves the performance\n",
    "\n",
    "---\n",
    "\n",
    "Tips\n",
    "\n",
    "1. using MB results to help regression task\n",
    "2. instead of fine-tuning datasets separately, you can fine-tune on all datasets together to improve generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Predicting MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "In the following, we describe a simple approach to estimate MB using TabPFN.\n",
    "\n",
    "A key characteristic of MB is that it remains the same for both the training and testing sets.\n",
    "Therefore, unlike standard target prediction tasks, we train TabPFN on MB from the training datasets \n",
    "and evaluate it on MB from the testing datasets.\n",
    "\n",
    "However, TabPFN natively supports only single-target prediction, so we need to adapt it for multi-output classification to predict the dimensions of MB.\n",
    "\n",
    "Another challenge is that different datasets have different MB dimensions.\n",
    "A simple solution is to train separate models for each MB dimension.\n",
    "In our case, there are only two MB sizes (9 and 19), so we train two independent models.\n",
    "\n",
    "Alternatively, one could pad MB vectors to a uniform size and train a single shared model across datasets.\n",
    "\n",
    "---\n",
    "\n",
    "Implementation details\n",
    "\n",
    "For each MB size, we train a model that maps  \n",
    "(n_dataset, n_estimators, n_samples, embedding_dim) -> (n_dataset, mb_dim)\n",
    "\n",
    "To achieve this, we proceed as follows:\n",
    "\n",
    "1. Compute embeddings of $X$ for each dataset using `nfold` to obtain more robust embeddings (https://arxiv.org/pdf/2502.17361).  \n",
    "   The resulting embeddings have shape (n_estimators * n_samples * embedding_dim = 192).\n",
    "2. Aggregate and reshape embeddings across estimators: \n",
    "   (n_dataset, n_estimators, n_samples, embedding_dim) -> (n_dataset * n_samples, embedding_dim).\n",
    "3. Expand MB labels accordingly:  \n",
    "   (n_dataset, mb_dim) -> (n_dataset * n_samples, mb_dim).\n",
    "4. Train a multi-output model (e.g., MultiOutputClassifier) on these processed embeddings.\n",
    "5. On the testing datasets, extract embeddings of $X$ and repeat step 2 for consistency.\n",
    "6. Predict MB for all samples, obtaining outputs of shape (n_dataset * n_samples, mb_dim).\n",
    "7. Aggregate predictions across samples within each dataset using a majority vote (or averaging with a 0.5 threshold) to recover dataset-level MB predictions:  \n",
    "   (n_dataset * n_samples, mb_dim) -> (n_dataset, mb_dim).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter mb size == 9\n",
    "# for the purpose of demo, we only use a subset of data with mb size 9\n",
    "data_mb9 = [d for d in develop if d['n_features'] == 9]\n",
    "train_data_mb9 = data_mb9[:20]  # use a smaller subset for faster demo\n",
    "test_data_mb9 = data_mb9[:10]  # use a smaller subset for faster demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TabPFN model\n",
    "regressor_config = {\n",
    "        \"ignore_pretraining_limits\": True,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"n_estimators\": 24,\n",
    "        \"random_state\":42,\n",
    "        \"inference_precision\": \"auto\"\n",
    "    }\n",
    "\n",
    "# --- Setup model ---\n",
    "regressor = TabPFNRegressor(\n",
    "    **regressor_config,\n",
    ")\n",
    "\n",
    "# create an embedding extractor\n",
    "embedding_extractor = TabPFNEmbedding(tabpfn_reg=regressor, n_fold=5)\n",
    "\n",
    "train_embeddings = []\n",
    "for d in tqdm(train_data_mb9):\n",
    "    train_embedding = embedding_extractor.get_embeddings(np.asarray(d['X_train']), np.asarray(d['y_train']), np.asarray(d['X_test']), data_source=\"train\")\n",
    "    train_embeddings.append(train_embedding)\n",
    "\n",
    "test_embeddings = []\n",
    "for d in tqdm(test_data_mb9):\n",
    "    test_embedding = embedding_extractor.get_embeddings(np.asarray(d['X_train']), np.asarray(d['y_train']), np.asarray(d['X_test']), data_source=\"test\")\n",
    "    test_embeddings.append(test_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(train_embeddings).shape # n_dataset * n_estimators * n_samples * embedding_dim (192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggreagte embeddings by n_estimators\n",
    "agg_embeddings = np.mean(np.stack(train_embeddings), axis=1).reshape(-1, 192)\n",
    "agg_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_train = np.stack([np.tile(d['feature_mask'], (d['n_train'], 1)) for d in train_data_mb9]).reshape(-1, 9)\n",
    "mb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultiOutputClassifier(LogisticRegression(), n_jobs=4).fit(agg_embeddings, mb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict, switch case\n",
    "test_embeddings_agg = np.mean(np.stack(test_embeddings), axis=1).reshape(-1, 192)\n",
    "test_embeddings_agg.shape\n",
    "\n",
    "predicted_mb = clf.predict(test_embeddings_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mb_new = predicted_mb.reshape(len(test_data_mb9), -1, 9)\n",
    "for d in range(len(test_data_mb9)):\n",
    "    pred_mb = np.mean(pred_mb_new[d, :], axis=0) >= 0.5\n",
    "    pred_mb = pred_mb.astype(int)\n",
    "    true_mb = np.asarray(test_data_mb9[d]['feature_mask'])\n",
    "\n",
    "    print(f\"True MB: {true_mb}\")\n",
    "    print(f\"Predicted MB: {pred_mb}\")\n",
    "    print(\"Jaccard Score: \", jaccard_score(true_mb, pred_mb))\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Tips\n",
    "\n",
    "1. MultiOutputClassifer treat each target independently, which is not ideal since mb features are correlated.\n",
    "2. Use a NN model to better predict mb from embedding (e.g. MLP, GNN, seq2seq etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "On submission dataset, for each dataset (data_id), predict both `y` and `markov_blanket`, and save results in `submission.csv` with the following format:\n",
    "\n",
    "| data_id | y_pred | markov_blanket_pred |\n",
    "|---------|--------|---------------------|\n",
    "| int     | float  | list of int         |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "For each dataset $j$ in `submit` with testing set $\\mathcal{D}^{(j)}_{\\text{test}}$ we compute:\n",
    "\n",
    "- **RMSE** on regression:\n",
    "$$ \\text{RMSE}_j = \\sqrt{\\frac{1}{N_{\\text{test}}} \\sum_{(x, y) \\in \\mathcal{D}^{(j)}_{\\text{test}}} (y - \\hat{y}(x))^2 }. $$\n",
    "- **Jaccard score** on MB masks:\n",
    "$$ \\text{Jaccard}_j = \\frac{|\\hat{m}^{(j)} \\cap m^{(j)}_{\\text{true}}|}{|\\hat{m}^{(j)} \\cup m^{(j)}_{\\text{true}}|}. $$\n",
    "\n",
    "Averaging over $N$ tasks gives $\\overline{\\text{RMSE}}$ and $\\overline{\\text{Jaccard}}$, and\n",
    "the final challenge **score** is\n",
    "$$ \\text{Score} = avg(RMSE_i * (1 - Jaccard_i)). $$\n",
    "\n",
    "- On the **develop test**, you can compute this score yourself.\n",
    "- On the **submission test**, the organizers run the same computation on a\n",
    "  hidden set of tasks.\n",
    "- Ground truth data will be released after the challenge ends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_task(\n",
    "    y_query_true: np.ndarray,\n",
    "    y_query_pred: np.ndarray,\n",
    "    mb_true: np.ndarray,\n",
    "    mb_pred: np.ndarray,\n",
    ") -> dict:\n",
    "    rmse_val = rmse(y_query_true, y_query_pred)\n",
    "    jaccard_val = jaccard_score(mb_true, mb_pred)\n",
    "    score_val = rmse_val * (1.0 - jaccard_val)\n",
    "    return {\"rmse\": rmse_val, \"jaccard\": jaccard_val, \"score\": score_val}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
