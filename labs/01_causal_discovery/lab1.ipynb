{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Lab 1: Causal Discovery based Markov Blanket Search\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading datasets and visualizing the DAG\n",
    "2. Introducing Causal Discovery based Markov Blanket Search methods (CD-MB)\n",
    "   - Evaluating causal discovery performance (NHD, precision, recall, F1)\n",
    "   - Evaluating Markov Blanket feature selection performance\n",
    "3. Comparing CD-MB methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a \"Muhammed Hunaid Topiwala\" -v\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import snapshot_download\n",
    "from datasets import load_dataset\n",
    "\n",
    "from blanket.datasets import load_data\n",
    "from blanket.feature_selection import (\n",
    "    direct_lingam_selector,\n",
    "    ges_selector,\n",
    "    notears_selector,\n",
    "    pc_selector,\n",
    ")\n",
    "from blanket.metrics import adjacency_confusion, jaccard_score, reduction_rate, shd\n",
    "from blanket.plots import plot_adjmat, plot_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Load Dataset and Visualize DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "datasets = load_dataset(path=\"CSE472-blanket-challenge/phase1-dataset\", split=\"train\")\n",
    "\n",
    "datasets.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = datasets[70]\n",
    "X = np.asarray(example[\"X\"])\n",
    "y = np.asarray(example[\"y\"])\n",
    "adj_mat = np.asarray(example[\"adjacency_matrix\"])\n",
    "num_nodes = example[\"num_nodes\"]\n",
    "density = example[\"density\"]\n",
    "mb = np.asarray(example[\"feature_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize True DAG and Adjacency Matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(17, 8), constrained_layout=True)\n",
    "\n",
    "plot_graph(adj_mat, figsize=(5, 5), ax=axes[0], title=\"True DAG\")\n",
    "\n",
    "plot_adjmat(\n",
    "    adj_mat,\n",
    "    title=\"Adjacency Matrix\",\n",
    "    figsize=(5, 5),\n",
    "    ax=axes[1],\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 2. Causal Discovery based Markov Blanket Search (CD-MB)\n",
    "\n",
    "The goal is to recover a target variable's Markov blanket (its parents, children, and spouses) by first learning a causal graph and then extracting the local neighborhood.\n",
    "\n",
    "General Workflow\n",
    "- Run a causal discovery algorithm on the data.\n",
    "- Sanitize the learned graph (e.g., remove implausible edges, orient CPDAG edges if needed, ensure acyclicity).\n",
    "- Extract the target's Markov blanket from the cleaned graph.\n",
    "\n",
    "Pros\n",
    "- Works with any causal discovery algorithm.\n",
    "- One learned graph can be reused for multiple target variables.\n",
    "\n",
    "Cons\n",
    "- Algorithm assumptions matter (e.g., causal sufficiency, faithfulness, linearity, non‑Gaussianity).\n",
    "- More often than not, CD method can not return a DAG but a CPDAG (equivalence class of DAGs).\n",
    "- Many CD methods do not scale well on high‑dimensional data.\n",
    "- Global structure learning can be wasteful when only a local (MB) neighborhood is needed.\n",
    "\n",
    "In this tutorial we compare four families of causal discovery methods:\n",
    "- PC — constraint‑based.\n",
    "- GES — score‑based.\n",
    "- DirectLiNGAM — functional/ICA‑based (non‑Gaussian noise).\n",
    "- NOTEARS — gradient/continuous optimization‑based (linear SEM with acyclicity penalty).\n",
    "\n",
    "We use the [`gCastle`](https://github.com/huawei-noah/trustworthyAI/blob/master/gcastle) package for the causal discovery algorithms; see its documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_feature, pc_adjmat = pc_selector(X, y, alpha=0.05, ci_test=\"fisherz\", variant=\"stable\")\n",
    "ges_feature, ges_adjmat = ges_selector(X, y, criterion=\"bic\", method=\"scatter\")\n",
    "direct_lingam_feature, direct_lingam_adjmat = direct_lingam_selector(\n",
    "    X, y, measure=\"pwling\", thresh=0.3\n",
    ")\n",
    "notears_feature, notears_adjmat = notears_selector(X, y, lambda1=0.1, loss_type=\"l2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Some CD algos returns a class of graph called CPDAG, CPDAG contains undirected edges when the direction cannot be determined from conditional independence tests alone.\n",
    "\n",
    "For MB, we allow bidirectional edges\n",
    "\n",
    "Some causal discovery methods return a CPDAG*, an equivalence class that includes undirected edges when orientation cannot be determined from conditional independence tests alone. For Markov‑blanket extraction, a partially oriented graph is acceptable; we permit undirected (bidirectional) edges. The minimal Markov blanket is known as the Markov boundary.\n",
    "\n",
    "\\*: Proposition 11.1, Introduction to Causal Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_numpy_array(pc_adjmat, create_using=nx.DiGraph)\n",
    "nx.is_directed_acyclic_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute graph metrics (SHD, precision, recall, F1) and MB metrics for each discovered graph\n",
    "\n",
    "cdmb_results = {\n",
    "    \"PC\": (pc_feature, pc_adjmat),\n",
    "    \"GES\": (ges_feature, ges_adjmat),\n",
    "    \"DirectLiNGAM\": (direct_lingam_feature, direct_lingam_adjmat),\n",
    "    \"NOTEARS\": (notears_feature, notears_adjmat),\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, results in cdmb_results.items():\n",
    "    feature = results[0]\n",
    "    adj = results[1]\n",
    "    shd_val = shd(adj_mat, adj)\n",
    "    precision, recall, f1 = adjacency_confusion(adj_mat, adj)\n",
    "\n",
    "    mb_jaccard = jaccard_score(mb, feature)\n",
    "    mb_size = int(np.sum(feature))\n",
    "    mb_reduction = reduction_rate(feature)\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"Method\": name,\n",
    "            \"SHD\": int(shd_val),\n",
    "            \"Precision\": float(precision),\n",
    "            \"Recall\": float(recall),\n",
    "            \"F1 Score\": float(f1),\n",
    "            \"MB Jaccard\": float(mb_jaccard),\n",
    "            \"MB Size\": mb_size,\n",
    "            \"Reduction Rate\": float(mb_reduction),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create and display comparison table\n",
    "comparison_df = pd.DataFrame(rows)\n",
    "comparison_df.sort_values(by=\"F1 Score\", ascending=False, inplace=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "From the result above, NoTEARS performs best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the results\n",
    "\n",
    "num_methods = len(cdmb_results)\n",
    "fig, axes = plt.subplots(2, num_methods + 1, figsize=(num_methods * 8, 12), constrained_layout=True)\n",
    "\n",
    "plot_graph(\n",
    "    adj_mat,\n",
    "    figsize=(5, 5),\n",
    "    title=\"True DAG\",\n",
    "    ax=axes[0, 0],\n",
    ")\n",
    "\n",
    "plot_adjmat(\n",
    "    adj_mat,\n",
    "    title=\"True Adjacency Matrix\",\n",
    "    figsize=(5, 5),\n",
    "    ax=axes[1, 0],\n",
    ")\n",
    "\n",
    "for i, (name, results) in enumerate(cdmb_results.items(), 1):\n",
    "    adj = results[1]\n",
    "    plot_graph(\n",
    "        adj,\n",
    "        figsize=(5, 5),\n",
    "        title=f\"{name}\",\n",
    "        ax=axes[0, i],\n",
    "    )\n",
    "\n",
    "    plot_adjmat(\n",
    "        adj,\n",
    "        title=f\"{name}\",\n",
    "        figsize=(5, 5),\n",
    "        ax=axes[1, i],\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 4. Scale up\n",
    "\n",
    "The above is just a small demo on one graph. Next, we run all CD-MB methods on 10 graphs, record time, and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample 10 graphs from the dataset\n",
    "n_graphs = 10\n",
    "sample_indices = np.random.choice(len(datasets), size=n_graphs, replace=False)\n",
    "\n",
    "# Initialize results storage\n",
    "all_results = []\n",
    "\n",
    "# Run all CD algos on each sampled graph\n",
    "for idx, sample_idx in enumerate(tqdm(sample_indices, total=n_graphs, desc=\"Processing graphs\", unit=\"graph\")):\n",
    "\n",
    "    example = datasets[sample_idx]\n",
    "\n",
    "    # Reconstruct the DAG from adjacency matrix\n",
    "    X = np.asarray(example[\"X\"])\n",
    "    y = np.asarray(example[\"y\"])\n",
    "    adj_mat = np.asarray(example[\"adjacency_matrix\"])\n",
    "    num_nodes = example[\"num_nodes\"]\n",
    "    num_edges = example[\"num_edges\"]\n",
    "    density = example[\"density\"]\n",
    "    oracle_mb = np.asarray(example[\"feature_mask\"])\n",
    "\n",
    "    # Run each algorithm and record time and results\n",
    "    algorithms = {\n",
    "        \"PC\": lambda: pc_selector(X, y, alpha=0.05, ci_test=\"fisherz\", variant=\"stable\"),\n",
    "        \"GES\": lambda: ges_selector(X, y, criterion=\"bic\", method=\"scatter\"),\n",
    "        \"DirectLiNGAM\": lambda: direct_lingam_selector(X, y, measure=\"pwling\", thresh=0.3),\n",
    "        \"NOTEARS\": lambda: notears_selector(X, y, lambda1=0.1, loss_type=\"l2\"),\n",
    "    }\n",
    "\n",
    "    for algo_name, algo_func in algorithms.items():\n",
    "        # Record time\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            feature, discovered_adj = algo_func()\n",
    "            end_time = time.time()\n",
    "            runtime = end_time - start_time\n",
    "\n",
    "            # Compute graph discovery metrics\n",
    "            shd_val = shd(adj_mat, discovered_adj)\n",
    "            precision, recall, f1 = adjacency_confusion(adj_mat, discovered_adj)\n",
    "\n",
    "            # Compute MB metrics\n",
    "            mb_jaccard = jaccard_score(oracle_mb, feature)\n",
    "            mb_size = int(np.sum(feature))\n",
    "            mb_reduction = reduction_rate(feature)\n",
    "            oracle_mb_size = int(np.sum(oracle_mb))\n",
    "\n",
    "            # Store results\n",
    "            all_results.append({\n",
    "                \"Graph Index\": sample_idx,\n",
    "                \"Graph ID\": idx + 1,\n",
    "                \"Algorithm\": algo_name,\n",
    "                \"Runtime (s)\": runtime,\n",
    "                \"Num Nodes\": num_nodes,\n",
    "                \"Num Edges\": num_edges,\n",
    "                \"Density\": density,\n",
    "                \"Oracle MB Size\": oracle_mb_size,\n",
    "                \"SHD\": int(shd_val),\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1 Score\": f1,\n",
    "                \"MB Jaccard\": mb_jaccard,\n",
    "                \"MB Size\": mb_size,\n",
    "                \"Reduction Rate\": mb_reduction,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"  Error in {algo_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary by algorithm\n",
    "summary_by_algo = results_df.groupby(\"Algorithm\").agg({\n",
    "    \"Runtime (s)\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "    \"SHD\": [\"mean\", \"std\"],\n",
    "    \"Precision\": [\"mean\", \"std\"],\n",
    "    \"Recall\": [\"mean\", \"std\"],\n",
    "    \"F1 Score\": [\"mean\", \"std\"],\n",
    "    \"MB Jaccard\": [\"mean\", \"std\"],\n",
    "    \"Reduction Rate\": [\"mean\", \"std\"],\n",
    "}).round(4)\n",
    "\n",
    "summary_by_algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 4.1 Compare Algorithm Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table: Runtime Performance\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY: RUNTIME PERFORMANCE BY ALGORITHM\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "runtime_summary = results_df.groupby(\"Algorithm\")[\"Runtime (s)\"].agg([\"count\", \"mean\", \"std\", \"min\", \"max\"]).round(4)\n",
    "runtime_summary.columns = [\"Count\", \"Mean (s)\", \"Std (s)\", \"Min (s)\", \"Max (s)\"]\n",
    "runtime_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color palette for algorithms\n",
    "algo_colors = {\n",
    "    \"PC\": \"#1f77b4\",\n",
    "    \"GES\": \"#ff7f0e\",\n",
    "    \"DirectLiNGAM\": \"#2ca02c\",\n",
    "    \"NOTEARS\": \"#d62728\"\n",
    "}\n",
    "\n",
    "# Create figure with subplots for Runtime vs Graph Properties\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), constrained_layout=True)\n",
    "\n",
    "# Plot 1: Runtime vs Num Nodes\n",
    "for algo in results_df[\"Algorithm\"].unique():\n",
    "    algo_data = results_df[results_df[\"Algorithm\"] == algo]\n",
    "    axes[0].scatter(algo_data[\"Num Nodes\"], algo_data[\"Runtime (s)\"],\n",
    "                   label=algo, s=100, alpha=0.7, color=algo_colors[algo])\n",
    "\n",
    "axes[0].set_xlabel(\"Number of Nodes\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Runtime (seconds)\", fontsize=12)\n",
    "axes[0].set_title(\"Runtime vs Number of Nodes\", fontsize=13, fontweight=\"bold\")\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Runtime vs Density\n",
    "for algo in results_df[\"Algorithm\"].unique():\n",
    "    algo_data = results_df[results_df[\"Algorithm\"] == algo]\n",
    "    axes[1].scatter(algo_data[\"Density\"], algo_data[\"Runtime (s)\"],\n",
    "                   label=algo, s=100, alpha=0.7, color=algo_colors[algo])\n",
    "\n",
    "axes[1].set_xlabel(\"Graph Density\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Runtime (seconds)\", fontsize=12)\n",
    "axes[1].set_title(\"Runtime vs Graph Density\", fontsize=13, fontweight=\"bold\")\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"1. Runtime Performance Analysis\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table: Graph Discovery Performance (F1 Score)\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY: GRAPH DISCOVERY PERFORMANCE (F1 SCORE) BY ALGORITHM\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "f1_summary = results_df.groupby(\"Algorithm\")[[\"SHD\", \"Precision\", \"Recall\", \"F1 Score\"]].agg([\"mean\", \"std\"]).round(4)\n",
    "f1_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Note that I did not optimize hyperparameters for each method; better performance may be possible with tuning.\n",
    "\n",
    "F1 score std is fairly high compared to mean, indicating one hyperparameter setting may not fit all graphs well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots for F1 Score vs Graph Properties\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), constrained_layout=True)\n",
    "\n",
    "# Plot 1: F1 Score vs Num Nodes\n",
    "for algo in results_df[\"Algorithm\"].unique():\n",
    "    algo_data = results_df[results_df[\"Algorithm\"] == algo]\n",
    "    axes[0].scatter(algo_data[\"Num Nodes\"], algo_data[\"F1 Score\"],\n",
    "                   label=algo, s=100, alpha=0.7, color=algo_colors[algo])\n",
    "\n",
    "axes[0].set_xlabel(\"Number of Nodes\", fontsize=12)\n",
    "axes[0].set_ylabel(\"F1 Score\", fontsize=12)\n",
    "axes[0].set_title(\"F1 Score vs Number of Nodes\", fontsize=13, fontweight=\"bold\")\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim([0, 1.05])\n",
    "\n",
    "# Plot 2: F1 Score vs Density\n",
    "for algo in results_df[\"Algorithm\"].unique():\n",
    "    algo_data = results_df[results_df[\"Algorithm\"] == algo]\n",
    "    axes[1].scatter(algo_data[\"Density\"], algo_data[\"F1 Score\"],\n",
    "                   label=algo, s=100, alpha=0.7, color=algo_colors[algo])\n",
    "\n",
    "axes[1].set_xlabel(\"Graph Density\", fontsize=12)\n",
    "axes[1].set_ylabel(\"F1 Score\", fontsize=12)\n",
    "axes[1].set_title(\"F1 Score vs Graph Density\", fontsize=13, fontweight=\"bold\")\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, 1.05])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table: Markov Blanket Feature Selection Performance\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY: MARKOV BLANKET FEATURE SELECTION PERFORMANCE BY ALGORITHM\")\n",
    "print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "mb_summary = results_df.groupby(\"Algorithm\")[[\"MB Jaccard\", \"MB Size\", \"Reduction Rate\"]].agg([\"mean\", \"std\"]).round(4)\n",
    "print(mb_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "MB performance is aligned with graph discovery performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots for Jaccard Similarity vs Graph Properties\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), constrained_layout=True)\n",
    "\n",
    "# Plot 1: MB Jaccard vs Num Nodes\n",
    "for algo in results_df[\"Algorithm\"].unique():\n",
    "    algo_data = results_df[results_df[\"Algorithm\"] == algo]\n",
    "    axes[0].scatter(algo_data[\"Num Nodes\"], algo_data[\"MB Jaccard\"],\n",
    "                   label=algo, s=100, alpha=0.7, color=algo_colors[algo])\n",
    "\n",
    "axes[0].set_xlabel(\"Number of Nodes\", fontsize=12)\n",
    "axes[0].set_ylabel(\"Markov Blanket Jaccard Similarity\", fontsize=12)\n",
    "axes[0].set_title(\"MB Jaccard Similarity vs Number of Nodes\", fontsize=13, fontweight=\"bold\")\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim([0, 1.05])\n",
    "\n",
    "# Plot 2: MB Jaccard vs Density\n",
    "for algo in results_df[\"Algorithm\"].unique():\n",
    "    algo_data = results_df[results_df[\"Algorithm\"] == algo]\n",
    "    axes[1].scatter(algo_data[\"Density\"], algo_data[\"MB Jaccard\"],\n",
    "                   label=algo, s=100, alpha=0.7, color=algo_colors[algo])\n",
    "\n",
    "axes[1].set_xlabel(\"Graph Density\", fontsize=12)\n",
    "axes[1].set_ylabel(\"Markov Blanket Jaccard Similarity\", fontsize=12)\n",
    "axes[1].set_title(\"MB Jaccard Similarity vs Graph Density\", fontsize=13, fontweight=\"bold\")\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([0, 1.05])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 4.2 Markov Blanket Analysis: Relationship between MB Size, Density, and Graph Structure\n",
    "\n",
    "By definition, a MB of $Y$ shield $Y$ from the rest of the features:\n",
    "\n",
    "$$P(Y | MB(Y), Z) = P(Y | MB(Y))$$\n",
    "\n",
    ",where $Z \\in X\\setminus \\{Y, MB(Y)\\}$.\n",
    "\n",
    "From this definition, we can infer that the all features, i.e $X \\setminus \\{Y\\}$, is a trivial MB of $Y$.\n",
    "\n",
    "Therefore, if a MB is close to the size of all features, it is not very useful to do MB search.\n",
    "In the following, for each graph, we iterate through all nodes and calculate their MBs to understand how MB size relates to graph density and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blanket.graph import get_markov_blanket\n",
    "\n",
    "# Compute MB for all nodes in each graph\n",
    "mb_analysis_data = []\n",
    "\n",
    "for graph_idx, sample_idx in enumerate(sample_indices):\n",
    "    example = datasets[sample_idx]\n",
    "    adj_mat = np.asarray(example[\"adjacency_matrix\"])\n",
    "    num_nodes = example[\"num_nodes\"]\n",
    "    num_edges = example[\"num_edges\"]\n",
    "    density = example[\"density\"]\n",
    "\n",
    "    # Compute MB for each node\n",
    "    for node_id in range(num_nodes):\n",
    "        mb = get_markov_blanket(adj_mat, node_id)\n",
    "        mb_size = sum(mb)\n",
    "        mb_ratio = mb_size / (num_nodes - 1)\n",
    "\n",
    "        mb_analysis_data.append({\n",
    "            \"Graph Index\": sample_idx,\n",
    "            \"Graph ID\": graph_idx + 1,\n",
    "            \"Node ID\": node_id,\n",
    "            \"Num Nodes\": num_nodes,\n",
    "            \"Num Edges\": num_edges,\n",
    "            \"Density\": density,\n",
    "            \"MB Size\": mb_size,\n",
    "            \"MB Ratio\": mb_ratio,\n",
    "        })\n",
    "\n",
    "mb_analysis_df = pd.DataFrame(mb_analysis_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_analysis_df.groupby(\"Graph ID\")[[\"MB Ratio\", \"Density\", \"Num Nodes\"]].agg([\"mean\", \"std\"]).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "1. When density exceeds 0.2, the average MB ratio is over 0.7. Noted that it already includes trivial nodes such as the root node with a limited MB. In practice, target variables are typically meaningful and thus not trivial. Hence, the average MB ratio could even be larger.\n",
    "2. Consequently, in many cases, identifying the MB is not particularly informative.\n",
    "3. It may seem counterintuitive, but densities of 0.1–0.2 are not sparse. Truly sparse graphs usually have densities below 0.001, which generally requires a large number of nodes (>1000). We leave this for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate MB Ratio by Graph ID\n",
    "aggregated_mb_df = mb_analysis_df.groupby(\"Graph ID\").agg({\n",
    "    \"MB Ratio\": \"mean\",\n",
    "    \"Density\": \"mean\",\n",
    "    \"Num Nodes\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Visualization: Aggregated MB Ratio vs Graph Properties (colored by Graph ID)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5), constrained_layout=True)\n",
    "\n",
    "# Plot 1: Aggregated MB Ratio vs Density with Graph ID coloring\n",
    "scatter1 = axes[0].scatter(aggregated_mb_df[\"Density\"], aggregated_mb_df[\"MB Ratio\"],\n",
    "                           c=aggregated_mb_df[\"Graph ID\"], cmap=\"tab10\",\n",
    "                           s=100, alpha=0.8, edgecolors=\"black\", linewidth=0.5)\n",
    "axes[0].set_xlabel(\"Graph Density\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"MB Ratio\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Aggregated MB Ratio vs Graph Density\", fontsize=13, fontweight=\"bold\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "cbar1 = plt.colorbar(scatter1, ax=axes[0])\n",
    "cbar1.set_label(\"Graph ID\", fontsize=11)\n",
    "\n",
    "# Plot 2: Aggregated MB Ratio vs Num Nodes with Graph ID coloring\n",
    "scatter2 = axes[1].scatter(aggregated_mb_df[\"Num Nodes\"], aggregated_mb_df[\"MB Ratio\"],\n",
    "                           c=aggregated_mb_df[\"Graph ID\"], cmap=\"tab10\",\n",
    "                           s=100, alpha=0.8, edgecolors=\"black\", linewidth=0.5)\n",
    "axes[1].set_xlabel(\"Number of Nodes\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"MB Ratio\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"Aggregated MB Ratio vs Number of Nodes\", fontsize=13, fontweight=\"bold\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "cbar2 = plt.colorbar(scatter2, ax=axes[1])\n",
    "cbar2.set_label(\"Graph ID\", fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "1. [5 point] Implement a specialized causal feature selection method (IAMB)\n",
    "- [bnlearn](https://github.com/cran/bnlearn) implements IAMB, fastIAMB. Using [rpy2](https://rpy2.github.io/) or write a R script to run it (if you're familiar with R).\n",
    "- [py-tetrad](https://github.com/cmu-phil/py-tetrad) also provides IAMB implementations.\n",
    "2. Is dedicated causal feature selection method (IAMB) working better than causal discovery methods?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}